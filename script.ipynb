{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "W5-4W4jxl7pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading"
      ],
      "metadata": {
        "id": "W_jbwGD_lnzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "si-q8w40lpo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV\n",
        "train = pd.read_csv('wcpr_mypersonality.csv', dtype=object, encoding='cp1252')\n",
        "\n",
        "# Fill NAs\n",
        "train.iloc[6399, 13:] = train.iloc[6399, 12:-1]\n",
        "train.iloc[6399, 12] = None  # Missing date\n",
        "\n",
        "# Rename columns\n",
        "train = train.rename(columns={\n",
        "    '#AUTHID': 'id',\n",
        "    'STATUS': 'status',\n",
        "    'sEXT': 'extraversion_score',\n",
        "    'sNEU': 'neuroticism_score',\n",
        "    'sAGR': 'agreeableness_score',\n",
        "    'sCON': 'conscientiousness_score',\n",
        "    'sOPN': 'openness_score',\n",
        "    'cEXT': 'extraversion_class',\n",
        "    'cNEU': 'neuroticism_class',\n",
        "    'cAGR': 'agreeableness_class',\n",
        "    'cCON': 'conscientiousness_class',\n",
        "    'cOPN': 'openness_class',\n",
        "    'DATE': 'date',\n",
        "    'NETWORKSIZE': 'network_size',\n",
        "    'BETWEENNESS': 'betweenness_raw',\n",
        "    'NBETWEENNESS': 'betweenness_normalized',\n",
        "    'DENSITY': 'density',\n",
        "    'BROKERAGE': 'brokerage_raw',\n",
        "    'NBROKERAGE': 'brokerage_normalized',\n",
        "    'TRANSITIVITY': 'transitivity'\n",
        "})\n",
        "\n",
        "# Relabel classes\n",
        "train = train.replace({\n",
        "    'extraversion_class': {'y': 'sociable', 'n': 'shy'},\n",
        "    'neuroticism_class': {'y': 'neurotic', 'n': 'calm'},\n",
        "    'agreeableness_class': {'y': 'friendly', 'n': 'uncooperative'},\n",
        "    'conscientiousness_class': {'y': 'organized', 'n': 'careless'},\n",
        "    'openness_class': {'y': 'insightful', 'n': 'unimaginative'}\n",
        "})\n",
        "\n",
        "# Cast dtypes\n",
        "train = train.astype({\n",
        "    'id': 'category',\n",
        "    'status': 'string',\n",
        "    'extraversion_score': 'float32',\n",
        "    'neuroticism_score': 'float32',\n",
        "    'agreeableness_score': 'float32',\n",
        "    'conscientiousness_score': 'float32',\n",
        "    'openness_score': 'float32',\n",
        "    'extraversion_class': 'category',\n",
        "    'neuroticism_class': 'category',\n",
        "    'agreeableness_class': 'category',\n",
        "    'conscientiousness_class': 'category',\n",
        "    'openness_class': 'category',\n",
        "    'date': 'datetime64[ns]',\n",
        "    'network_size': 'uint16',\n",
        "    'betweenness_raw': 'float32',\n",
        "    'betweenness_normalized': 'float32',\n",
        "    'density': 'float32',\n",
        "    'brokerage_raw': 'uint32',\n",
        "    'brokerage_normalized': 'float32',\n",
        "    'transitivity': 'float32'\n",
        "})\n",
        "\n",
        "# Group rows and filter columns\n",
        "train = train.groupby(['id', 'neuroticism_class'], observed=True)['status']\n",
        "train = train.agg(' '.join).reset_index()\n",
        "train = train[['status', 'neuroticism_class']]\n",
        "\n",
        "# Show train\n",
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOYFcF8ANw0w",
        "outputId": "2ffcf783-15d6-4dc0-ba66-31896001771e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 250 entries, 0 to 249\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype   \n",
            "---  ------             --------------  -----   \n",
            " 0   status             250 non-null    string  \n",
            " 1   neuroticism_class  250 non-null    category\n",
            "dtypes: category(1), string(1)\n",
            "memory usage: 2.4 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "ce4bWV7flrCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV\n",
        "test = pd.read_csv('wcpr_essays.csv', dtype=object, encoding='cp1252')\n",
        "\n",
        "# Rename columns\n",
        "test = test.rename(columns={\n",
        "    '#AUTHID': 'id',\n",
        "    'TEXT': 'text',\n",
        "    'cEXT': 'extraversion_class',\n",
        "    'cNEU': 'neuroticism_class',\n",
        "    'cAGR': 'agreeableness_class',\n",
        "    'cCON': 'conscientiousness_class',\n",
        "    'cOPN': 'openness_class'\n",
        "})\n",
        "\n",
        "# Relabel classes\n",
        "test = test.replace({\n",
        "    'extraversion_class': {'y': 'sociable', 'n': 'shy'},\n",
        "    'neuroticism_class': {'y': 'neurotic', 'n': 'calm'},\n",
        "    'agreeableness_class': {'y': 'friendly', 'n': 'uncooperative'},\n",
        "    'conscientiousness_class': {'y': 'organized', 'n': 'careless'},\n",
        "    'openness_class': {'y': 'insightful', 'n': 'unimaginative'}\n",
        "})\n",
        "\n",
        "# Cast dtypes\n",
        "test = test.astype({\n",
        "    'id': 'string',\n",
        "    'text': 'string',\n",
        "    'extraversion_class': 'category',\n",
        "    'neuroticism_class': 'category',\n",
        "    'agreeableness_class': 'category',\n",
        "    'conscientiousness_class': 'category',\n",
        "    'openness_class': 'category'\n",
        "})\n",
        "\n",
        "# Filter columns\n",
        "test = test[['text', 'neuroticism_class']]\n",
        "\n",
        "# Show test\n",
        "test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-RpamJbltYq",
        "outputId": "e3a0cc75-77f8-4d77-ffa4-4dafd53f714f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2468 entries, 0 to 2467\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype   \n",
            "---  ------             --------------  -----   \n",
            " 0   text               2468 non-null   string  \n",
            " 1   neuroticism_class  2468 non-null   category\n",
            "dtypes: category(1), string(1)\n",
            "memory usage: 21.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "M2BF4wf4luf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = Pipeline([\n",
        "    ('vectorizer', None),\n",
        "    ('classifier', None)\n",
        "])\n",
        "\n",
        "# Define hyperparameters\n",
        "params = [\n",
        "    {\n",
        "        \"vectorizer\": [\n",
        "            CountVectorizer(binary=True),\n",
        "            CountVectorizer(),\n",
        "            TfidfVectorizer()\n",
        "        ],\n",
        "        \"vectorizer__ngram_range\": [(1, 1), (2, 2)],\n",
        "        \"vectorizer__max_df\": [0.5, 1.0],\n",
        "        \"vectorizer__min_df\": [1, 2],\n",
        "        \"classifier\": [SVC()],\n",
        "        \"classifier__C\": [0.01, 0.1, 1, 10, 100],\n",
        "        \"classifier__kernel\": [\"linear\", \"rbf\"]\n",
        "    },\n",
        "    {\n",
        "        \"vectorizer\": [\n",
        "            CountVectorizer(binary=True),\n",
        "            CountVectorizer(),\n",
        "            TfidfVectorizer()\n",
        "        ],\n",
        "        \"vectorizer__ngram_range\": [(1, 1), (2, 2)],\n",
        "        \"vectorizer__max_df\": [0.5, 1.0],\n",
        "        \"vectorizer__min_df\": [1, 2],\n",
        "        \"classifier\": [KNeighborsClassifier()],\n",
        "        \"classifier__n_neighbors\": [1, 3, 5, 7, 9],\n",
        "        \"classifier__metric\": [\"euclidean\", \"cosine\"]\n",
        "    },\n",
        "    {\n",
        "        \"vectorizer\": [\n",
        "            CountVectorizer(binary=True),\n",
        "            CountVectorizer(),\n",
        "            TfidfVectorizer()\n",
        "        ],\n",
        "        \"vectorizer__ngram_range\": [(1, 1), (2, 2)],\n",
        "        \"vectorizer__max_df\": [0.5, 1.0],\n",
        "        \"vectorizer__min_df\": [1, 2],\n",
        "        \"classifier\": [RandomForestClassifier(random_state=641)]\n",
        "    },\n",
        "    {\n",
        "        \"vectorizer\": [\n",
        "            CountVectorizer(binary=True),\n",
        "            CountVectorizer(),\n",
        "            TfidfVectorizer()\n",
        "        ],\n",
        "        \"vectorizer__ngram_range\": [(1, 1), (2, 2)],\n",
        "        \"vectorizer__max_df\": [0.5, 1.0],\n",
        "        \"vectorizer__min_df\": [1, 2],\n",
        "        \"classifier\": [GradientBoostingClassifier(random_state=641)],\n",
        "        \"classifier__max_depth\": [1, 2, 3, 4, 5]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create folds\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=641)\n",
        "\n",
        "# Tune model\n",
        "grid = GridSearchCV(model, params, scoring='balanced_accuracy', cv=cv)\n",
        "grid.fit(train['status'], train['neuroticism_class'])\n",
        "\n",
        "# Save results\n",
        "with open('results.pkl', 'wb') as file:\n",
        "    pickle.dump(grid.cv_results_, file)\n",
        "\n",
        "# Show results\n",
        "print(f'''Pipeline([\n",
        "    {grid.best_estimator_.steps[0]},\n",
        "    {grid.best_estimator_.steps[1]}\n",
        "])''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxdrXf4ml3Bs",
        "outputId": "89eefc92-d627-4332-a178-b93ca9bc5825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline([\n",
            "    ('vectorizer', TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(2, 2)))\n",
            "    ('classifier', KNeighborsClassifier(metric='euclidean', n_neighbors=9))\n",
            "])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "fmm5cx-xl3WR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO98xpjklGqP",
        "outputId": "9139411a-793b-4374-9756-521dda10e119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        calm       0.51      0.47      0.49      1235\n",
            "    neurotic       0.51      0.55      0.53      1233\n",
            "\n",
            "    accuracy                           0.51      2468\n",
            "   macro avg       0.51      0.51      0.51      2468\n",
            "weighted avg       0.51      0.51      0.51      2468\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show results\n",
        "print(classification_report(\n",
        "    test['neuroticism_class'],\n",
        "    grid.predict(test['text'])\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra"
      ],
      "metadata": {
        "id": "3AjUDPV-ll78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "class DenseTransformer(TransformerMixin, BaseEstimator):\n",
        "    '''scikit-learn wrapper for scipy _spbase.toarray'''\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.toarray()"
      ],
      "metadata": {
        "id": "T4mraPfOpudQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "class LemmaTokenizer:\n",
        "    '''Wrapper for NLTK WordNetLemmatizer.lemmatize'''\n",
        "\n",
        "    def __init__(self, *, token_pattern=None):\n",
        "        if token_pattern is None:\n",
        "            token_pattern = r'(?u)\\b\\w\\w+\\b'\n",
        "        self.tokenizer = re.compile(token_pattern).findall\n",
        "        self.lemmatizer = WordNetLemmatizer().lemmatize\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return [self.lemmatizer(t) for t in self.tokenizer(x)]"
      ],
      "metadata": {
        "id": "r1KBfQR0pz9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "class StemTokenizer:\n",
        "    '''Wrapper for NLTK PorterStemmer.stem'''\n",
        "\n",
        "    def __init__(self, *, token_pattern=None):\n",
        "        if token_pattern is None:\n",
        "            token_pattern = r'(?u)\\b\\w\\w+\\b'\n",
        "        self.tokenizer = re.compile(token_pattern).findall\n",
        "        self.stemmer = PorterStemmer().stem\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return [self.stemmer(t, to_lowercase=False) for t in self.tokenizer(x)]"
      ],
      "metadata": {
        "id": "xBNbrD49p1ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "class Word2Vectorizer(TransformerMixin, BaseEstimator):\n",
        "    '''scikit-learn wrapper for gensim Word2Vec'''\n",
        "\n",
        "    def __init__(self, *, analyzer=None):\n",
        "        if analyzer is None:\n",
        "            analyzer = HashingVectorizer().build_analyzer()\n",
        "        self.analyzer = analyzer\n",
        "        self.model_ = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.model_ = Word2Vec([self.analyzer(x) for x in X])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.vstack([self.model_.wv.get_mean_vector(self.analyzer(x)) for x in X])"
      ],
      "metadata": {
        "id": "pxh5genXlt5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _Regenerator:\n",
        "    '''Utility for Word2Vectorizer'''\n",
        "\n",
        "    def __init__(self, callback, iterable):\n",
        "        self.callback = callback\n",
        "        self.iterable = iterable\n",
        "        self.generator = None\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.generator = (self.callback(x) for x in self.iterable)\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        return next(self.generator)"
      ],
      "metadata": {
        "id": "5SJGw3_-BoPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "class Doc2Vectorizer(TransformerMixin, BaseEstimator):\n",
        "    '''scikit-learn wrapper for gensim Doc2Vec'''\n",
        "\n",
        "    def __init__(self, *, analyzer=None):\n",
        "        if analyzer is None:\n",
        "            analyzer = HashingVectorizer().build_analyzer()\n",
        "        self.analyzer = analyzer\n",
        "        self.model_ = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.model_ = Doc2Vec([TaggedDocument(self.analyzer(x), [i]) for i, x in enumerate(X)])\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.vstack([self.model_.infer_vector(self.analyzer(x)) for x in X])"
      ],
      "metadata": {
        "id": "Pfn5I1aArH80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _ERegenerator:\n",
        "    '''Utility for Doc2Vectorizer'''\n",
        "\n",
        "    def __init__(self, callback, iterable):\n",
        "        self.callback = callback\n",
        "        self.iterable = iterable\n",
        "        self.generator = None\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.generator = (self.callback(x, i) for i, x in enumerate(self.iterable))\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        return next(self.generator)"
      ],
      "metadata": {
        "id": "gJK9z1SNBmkR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}